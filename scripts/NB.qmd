---
title: "NB"
format: html
editor: visual
---

```{r}
library(bnlearn)
library(tidyverse)
```

```{r}
library(tidytext)
library(knitr)
library(stringr)
```

```{r}
texto = read.csv("../data/ghost_stories_1000.csv")
```

```{r}
texto <- texto |>
  mutate(category = str_trim(category),
         category = na_if(category, ""),
         category = if_else(is.na(category), "Unknown", category))

```

```{r}
library(dplyr)

 df <- texto |>
  filter(category %in% c("Haunted Places",
                         "Apparitions / Voices / Touches")) |>
  select(story_id, title, category, story)   

```

```{r}
df <- df %>%
  mutate(story_id = row_number())

write.csv(df, "../data/ghost_stories_filtered.csv", row.names = FALSE)
view(df)
```

```{r}
df |>
  distinct(category)
```

```{r}
df2 <- df %>%
  transmute(doc_id = story_id,
            category = category,
            text = story)
```

```{r}
words <- df2 |>
  unnest_tokens(word, text) |>
  filter(!str_detect(word, "^[0-9]+$"))        
```

```{r}
words |>
  count(category, word, sort = TRUE) |>
  group_by(category) |>
  slice_head(n = 10) |>
  pivot_wider(
    names_from = category, 
    values_from = n,
    values_fn = as.character,
    values_fill = "Not in top 10"
    ) |>
  kable()
```

```{r}
stop_words
```

```{r}
words <- words |>
  anti_join(stop_words, by = "word")
```

```{r}
words |>
  count(category, word, sort = TRUE) |>
  group_by(category) |>
  slice_head(n = 10) |>
  pivot_wider(
    names_from = category, 
    values_from = n,
    values_fn = as.character,
    values_fill = "Not in top 10"
    ) |>
  kable()
```

```{r}
words |>
  count(category, word, sort = TRUE) |>
  group_by(category) |>
  slice_head(n = 10) |>
  ggplot(aes(y = reorder_within(word, n, category), x = n, fill = category)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~category, scales = "free") +
  scale_y_reordered() +
  labs(y = NULL)
```

> Con estas repeticiones de palabras nos podemos dar una idea de como el modelo va a a predecir las categorias, ya que tomaría en cuenta la repetición y conteo de palabras por cada categoría.

Sparse Matrix

```{r}
library(Matrix) 
```

```{r}
tokens <- df2 |>
  unnest_tokens(word, text) |>
  filter(!str_detect(word, "^[0-9]+$")) |>
  anti_join(stop_words, by = "word")
```

```{r}
counts <- tokens |>
  count(doc_id, word, name = "freq")
```

```{r}
X <- cast_sparse(
  counts,
  row = doc_id,
  col = word,
  value = freq
)
```

```{r}
meta <- df2 |>
  distinct(doc_id, category)
```

```{r}
labels <- meta$category[match(as.integer(rownames(X)), meta$doc_id)]
```

Training/Test separation

```{r}
library(rsample)
```

```{r}
set.seed(123)
split <- initial_split(
                      tibble(doc_id = rownames(X),
                            category = labels),
                      prop = 0.8,
                      strata = category)
```

```{r}
train_ids <- training(split)$doc_id
test_ids  <- testing(split)$doc_id
```

```{r}
train_index <- match(train_ids, rownames(X))
test_index  <- match(test_ids, rownames(X))
```

```{r}
X_train <- X[train_index, ]
y_train <- labels[train_index]
```

```{r}
X_test  <- X[test_index, ]
y_test  <- labels[test_index]
```

```{r}
train_df <- as.data.frame(as.matrix(X_train))
train_df$category <- as.factor(y_train)
```

```{r}
library(e1071) 
library(yardstick)
```

```{r}
nb_model <- naiveBayes(category ~ ., data = train_df)
```

```{r}
test_df <- as.data.frame(as.matrix(X_test))
pred <- predict(nb_model, test_df)
```

#### Matriz de Confusión

```{r}
conf_mat <- table(Predicho = pred, Real = y_test)
print(conf_mat)
```

Clase real "Apparitions / Voices / Touches"

-   28 veces se predijo correctamente.

-   46 veces fueron mal clasificadas como esa clase cuando en realidad eran "Haunted Places".

Clase real "Haunted Places"

-   0 aciertos, el modelo nunca la predijo.

Esto ya explica el sesgo del clasificador: solo aprende a reconocer la clase mayoritaria.

#### Accuracy

```{r}
accuracy <- mean(pred == y_test)
cat("Accuracy:", accuracy, "\n")
```

Es bajo: el modelo acierta poco más de 1 de cada 3 casos.

#### Métricas por clase

```{r}
classes <- levels(y_test)

get_metrics <- function(k) {
  TP <- conf_mat[k, k]
  FP <- sum(conf_mat[k, ]) - TP
  FN <- sum(conf_mat[, k]) - TP
  P  <- if ((TP + FP) == 0) NA else TP / (TP + FP)
  R  <- if ((TP + FN) == 0) NA else TP / (TP + FN)
  F1 <- if (is.na(P) || is.na(R) || (P + R) == 0) NA else 2 * P * R / (P + R)
  c(Clase = k, Precision = P, Recall = R, F1 = F1)
}

metrics <- as.data.frame(do.call(rbind, lapply(classes, get_metrics)))
metrics$Precision <- as.numeric(metrics$Precision)
metrics$Recall    <- as.numeric(metrics$Recall)
metrics$F1        <- as.numeric(metrics$F1)

print(metrics)
```

Apparitions / Voices / Touches

Precisión (0.37): de todas las veces que el modelo predijo esta clase, solo el 37 % fueron correctas.

Recall (1.0): recuperó todos los casos reales de esta clase.

F1 (0.55): balance intermedio; refleja que aunque cubre todo (recall perfecto), se equivoca mucho al sobrepredecirla.

Haunted Places

Precisión = NA: nunca fue predicha → no hay aciertos.

Recall = 0: había ejemplos reales, pero el modelo no reconoció ninguno.

F1 = NA: no hay balance posible, ya que no predijo nada bien de esta clase.

#### Función naive_bayes()

```{r}
install.packages("naivebayes")
```

```{r}
library(naivebayes)
```

```{r}
nb_model2 <- naive_bayes(category ~ ., data = train_df)
```

```{r}
pred2 <- predict(nb_model2, newdata = test_df)
```

```{r}
conf_mat2 <- table(Predicho = pred2, Real = y_test)
print(conf_mat2)
```

```{r}
accuracy2 <- mean(pred2 == y_test)
cat("Accuracy (naive_bayes):", accuracy2, "\n")
```

No existe ninguna diferencia entre ambos clasificadores.

Dicotomizaremos el tipo de evento paranormal con ayuda de la función case_when()

```{r}
df2 <- df2 %>%
  mutate(category_bin = case_when(
    category == "Haunted Places" ~ "Haunted Places",
    TRUE ~ "Other"
  ))

labels_bin <- df2$category_bin[match(as.integer(rownames(X)), df2$doc_id)]
```

Naïve Bayes con ambas funciones:

```{r}
set.seed(123)
split_bin <- initial_split(
  tibble(doc_id = rownames(X),
         category = labels_bin),
  prop = 0.8,
  strata = category
)

train_ids_bin <- training(split_bin)$doc_id
test_ids_bin  <- testing(split_bin)$doc_id

train_index_bin <- match(train_ids_bin, rownames(X))
test_index_bin  <- match(test_ids_bin, rownames(X))

X_train_bin <- X[train_index_bin, ]
y_train_bin <- labels_bin[train_index_bin]

X_test_bin  <- X[test_index_bin, ]
y_test_bin  <- labels_bin[test_index_bin]

train_df_bin <- as.data.frame(as.matrix(X_train_bin))
train_df_bin$category <- as.factor(y_train_bin)

test_df_bin <- as.data.frame(as.matrix(X_test_bin))
```

```{r}
library(e1071)

nb_model_bin <- naiveBayes(category ~ ., data = train_df_bin, laplace = 1)
pred_bin <- predict(nb_model_bin, test_df_bin)

conf_mat_bin <- table(Predicho = pred_bin, Real = y_test_bin)
print(conf_mat_bin)

accuracy_bin <- mean(pred_bin == y_test_bin)
cat("Accuracy (binario - naiveBayes):", accuracy_bin, "\n")
```

```{r}
library(naivebayes)

nb_model2_bin <- naive_bayes(category ~ ., data = train_df_bin, laplace = 1)
pred2_bin <- predict(nb_model2_bin, newdata = test_df_bin)

conf_mat2_bin <- table(Predicho = pred2_bin, Real = y_test_bin)
print(conf_mat2_bin)

accuracy2_bin <- mean(pred2_bin == y_test_bin)
cat("Accuracy (binario - naive_bayes):", accuracy2_bin, "\n")
```

**NO** hubieron mejoras :c, Ahora implementaremos una distribucion de Poisson c:\<

```{r}
nb_model_poisson <- naive_bayes(category ~ ., 
                                data = train_df_bin, 
                                usepoisson = TRUE, 
                                laplace = 1)

pred_poisson <- predict(nb_model_poisson, newdata = test_df_bin)

conf_mat_poisson <- table(Predicho = pred_poisson, Real = y_test_bin)
print(conf_mat_poisson)

accuracy_poisson <- mean(pred_poisson == y_test_bin)
cat("Accuracy (binario - naive_bayes con Poisson):", accuracy_poisson, "\n")

```

Laplace smoothing:

```{r}
for (alpha in c(0, 0.5, 1, 2)) {
  model_tmp <- naiveBayes(category ~ ., data = train_df_bin, laplace = alpha)
  pred_tmp <- predict(model_tmp, test_df_bin)
  acc_tmp <- mean(pred_tmp == y_test_bin)
  cat("Laplace =", alpha, " → Accuracy:", acc_tmp, "\n")
}
```

Cross-validation:

```{r}
#Borren esto cuando ya la instalen lol - Pedro
install.packages("caret")
```

```{r}
library(caret)

# definimos CV estratificado en 5 folds
ctrl <- trainControl(method = "cv", number = 5)

# grid de posibles valores de laplace
grid <- expand.grid(laplace = c(0, 0.5, 1, 2),
                    usekernel = FALSE,
                    adjust = 1)

set.seed(123)
cv_model <- train(category ~ ., 
                  data = train_df_bin, 
                  method = "naive_bayes", 
                  trControl = ctrl,
                  tuneGrid = grid)

print(cv_model)
plot(cv_model)

```
